{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21192,
     "status": "ok",
     "timestamp": 1655810886585,
     "user": {
      "displayName": "bds meteo",
      "userId": "09881294319658969130"
     },
     "user_tz": -120
    },
    "id": "j50L7FqqmQmQ",
    "outputId": "5ff895b9-ca72-4eeb-f57c-34e933c4620c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1655810886589,
     "user": {
      "displayName": "bds meteo",
      "userId": "09881294319658969130"
     },
     "user_tz": -120
    },
    "id": "2AzrBkVHZ59M",
    "outputId": "6d40c5a0-ee83-45ac-cce5-69866738b664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/streamlit\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/Colab Notebooks/streamlit'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IL FAUT SE METTRE DANS LE REPERTOIRE CONTENANT LES FICHIERS\n",
    "%cd  \"/content/drive/MyDrive/Colab Notebooks/streamlit/\"\n",
    "%pwd #check the current work dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnH_hp8AXAfI"
   },
   "source": [
    "## **INSTALLATION DE STREAMLIT POUR COLAB**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18678,
     "status": "ok",
     "timestamp": 1655810905245,
     "user": {
      "displayName": "bds meteo",
      "userId": "09881294319658969130"
     },
     "user_tz": -120
    },
    "id": "IEC6y2arRY5y",
    "outputId": "c07f32dc-d6ac-4b0d-f430-1ddba6d4c606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 9.1 MB 4.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 164 kB 52.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 232 kB 59.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 111 kB 58.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 38.7 MB/s \n",
      "\u001b[K     |████████████████████████████████| 181 kB 55.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 78 kB 6.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 133 kB 61.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 428 kB 62.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 793 kB 21.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 132 kB 74.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 381 kB 72.7 MB/s \n",
      "\u001b[K     |████████████████████████████████| 51 kB 7.0 MB/s \n",
      "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "nbclient 0.6.4 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n",
      "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
      "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.0 which is incompatible.\n",
      "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install streamlit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6003,
     "status": "ok",
     "timestamp": 1655810911221,
     "user": {
      "displayName": "bds meteo",
      "userId": "09881294319658969130"
     },
     "user_tz": -120
    },
    "id": "_vFaxQbaE8RZ",
    "outputId": "9ab67486-e828-4ae7-dc7d-80b7bfc5eedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting streamlit-option-menu\n",
      "  Downloading streamlit_option_menu-0.3.2-py3-none-any.whl (712 kB)\n",
      "\u001b[K     |████████████████████████████████| 712 kB 5.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.7/dist-packages (from streamlit-option-menu) (1.10.0)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (0.7.1)\n",
      "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (4.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.21.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (7.1.2)\n",
      "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (6.1)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (2.8.2)\n",
      "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (0.20.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (2.23.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (7.1.2)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.5.1)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (21.4.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (0.10.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (6.0.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (12.4.4)\n",
      "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (4.2.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (4.1.1)\n",
      "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (4.11.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (21.3)\n",
      "Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (2.13.0)\n",
      "Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (2.1.9)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (3.1.27)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (3.17.3)\n",
      "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.0.1)\n",
      "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.63->streamlit-option-menu) (1.3.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-option-menu) (4.3.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-option-menu) (0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-option-menu) (2.11.3)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-option-menu) (0.11.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit>=0.63->streamlit-option-menu) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=0.63->streamlit-option-menu) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->streamlit>=0.63->streamlit-option-menu) (3.8.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.63->streamlit-option-menu) (5.7.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.63->streamlit-option-menu) (0.18.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit>=0.63->streamlit-option-menu) (2022.1)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.12->streamlit>=0.63->streamlit-option-menu) (1.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (5.1.1)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (6.15.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (7.7.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (1.0.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.1.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (5.4.8)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (7.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (1.5.5)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (7.34.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.18.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (57.4.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (3.0.29)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (2.6.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (4.8.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.2.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (1.1.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (5.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (3.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit>=0.63->streamlit-option-menu) (2.0.1)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (4.10.0)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (2.15.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (5.3.1)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (5.6.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.13.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.7.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (5.0.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit>=0.63->streamlit-option-menu) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit>=0.63->streamlit-option-menu) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit>=0.63->streamlit-option-menu) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit>=0.63->streamlit-option-menu) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit>=0.63->streamlit-option-menu) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit>=0.63->streamlit-option-menu) (1.24.3)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich->streamlit>=0.63->streamlit-option-menu) (0.9.1)\n",
      "Installing collected packages: streamlit-option-menu\n",
      "Successfully installed streamlit-option-menu-0.3.2\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit-option-menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phVCQmr7XKO3"
   },
   "source": [
    "## **ICI LE CODE STREAMLIT**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1655811952013,
     "user": {
      "displayName": "bds meteo",
      "userId": "09881294319658969130"
     },
     "user_tz": -120
    },
    "id": "2sRRfOkeRljV",
    "outputId": "c20e7c13-3853-44d9-f7e0-083b467c9662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "# on écrit le code ci-dessous dans le fichier app.py\n",
    "# qui va ensuite être exécuté pour lire le streamlit\n",
    "\n",
    "#######################\n",
    "##### LES IMPORTS #####\n",
    "#######################\n",
    "\n",
    "import sre_compile\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api\n",
    "import streamlit as st\n",
    "from streamlit_option_menu import option_menu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "##### INSTANCIATION DES VARIABLES GLOBALES #####\n",
    "################################################\n",
    "\n",
    "df_raw = pd.read_csv('weatherAUS_raw.csv')\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "##### PAGE DE GARDE  / INTRODUCTION #####\n",
    "#########################################\n",
    "\n",
    "def introduction():\n",
    "  st.title('Prévisions météo en Australie')\n",
    "  st.caption('projet ML pour formation bootcamp data scientist')\n",
    "\n",
    "  st.image('rainfallAUS.jpg')\n",
    "  st.caption('source : Australian Government Bureau of Meteorology Climate Data Online; copyright Commonwealth of Australia')\n",
    "\n",
    "  st.markdown(\"# Prédire s'il va pleuvoir le lendemain\")\n",
    "  st.markdown('''---''')\n",
    "  \n",
    "  st.markdown(\"#### Yassine HAMDAOUI, JingYi LIU, Julien PROST, Mohamed TOUMI\")\n",
    "  st.caption('Avril 2022 - Bootcamp Data scientist')\n",
    "  st.markdown('''---''')\n",
    "  \n",
    "  st.markdown(\"### Contexte et objectifs :\")\n",
    "  st.markdown(\"\"\"\n",
    "    Ce streamlit vise à traiter une problématique de classification dans le cadre d’un projet réalisé au cours de la formation bootcamp data scientist (avr 2022) avec Datascientest.  \\n\n",
    "    L’objectif de ce projet est de prédire s'il va pleuvoir le lendemain (j+1) sur la base des indicateurs météorologiques du jour actuel (j) en Australie.  \\n\n",
    "    L'ensemble de données contient des informations sur les observations météorologiques recueillies pendant dix ans auprès de diverses stations météorologiques australiennes. Le temps est défini comme « pluvieux » si les précipitations sont de 1 mm ou plus. Les données sont recueillies auprès du Bureau de météorologie du gouvernement australien. \n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "####################################################\n",
    "##### DATASET / PRESENTATION DU JEU DE DONNEES #####\n",
    "####################################################\n",
    "\n",
    "def dataset(df_dataset):\n",
    "  st.title('Présentation du jeu de données')\n",
    "\n",
    "  st.markdown(\"## Description du jeu de données et des variables\")\n",
    "  st.write(\"Le dataset utilisé pour ce projet provient du site Kaggle.com. Le lien est indiqué ci-dessous :\")\n",
    "  st.write(\"[lien vers le dataset](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package)\")\n",
    "  st.write(\"L'ensemble de données comprend 23 colonnes et 145 460 lignes.\")\n",
    "  st.write(\"Il existe des caractéristiques quantitatives telles que la température maximale et minimale, l'évaporation, la durée d'ensoleillement et la vitesse du vent, des caractéristiques qualitatives telles que les dates, les lieux, la direction du vent et deux caractéristiques catégorielles binaires (Yes, No) indiquant s'il a plu ce jour-là et s'il va pleuvoir le lendemain.\")\n",
    "\n",
    "  st.markdown(\"## Lecture du jeu de données\")\n",
    "  ## Lecture du jeu de données\n",
    "  with st.echo():       # pour afficher une partie du code\n",
    "    df = pd.read_csv('weatherAUS_raw.csv')\n",
    "\n",
    "  st.dataframe(df_dataset)\n",
    "\n",
    "  st.markdown(\"## Description statistique des variables\")\n",
    "  st.dataframe(df_dataset.describe())\n",
    "\n",
    "  st.write(\"On observe que les variables ont dans l’ensemble une répartition équilibrée, hormis les variables Pressure9am, Pressure3pm, RainToday et RainTomorrow qui sont très focalisées (rapport std/mean <15%).\")\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "##### ANALYSE EXPLORATOIRE DES DONNEES #####\n",
    "############################################\n",
    "\n",
    "def data_explore(df_explore):\n",
    "  st.title('Analyse exploratoire des données')\n",
    "  st.write(\"Ci-dessous, quelques premières visualisations pour quelques variables. Des visualisations complémentaires et plus poussées sont présentées dans le reste du document, notamment dans la partie sur la sélection des variables.\")\n",
    "  st.write(\"Nous présentons ensuite le nettoyage et le preprocessing des données.\")  \n",
    "\n",
    "  st.markdown(\"<style>.streamlit-expanderHeader {font-size: xx-large;}</style>\",unsafe_allow_html=True)   # pour configurer la police de st.expander\n",
    "  with st.expander(\"Visualisations\"):\n",
    "  #  st.markdown(\"## Visualisations\")\n",
    "    graph_choisi = st.selectbox(label = 'choix du graphique', \n",
    "                                options = ['Distribution de fréquence de la variable RainTomorrow', \n",
    "                                          'Corrélation entre ensoleillement et précipitation en mm', \n",
    "                                          'Corrélation entre ensoleillement et évaporation',\n",
    "                                          'Corrélation entre nuages et pluie le lendemain',\n",
    "                                          'corrélation entre humidité et RainTomorrow', \n",
    "                                          'Influence des saisons', \n",
    "                                          'Influence de la pression atomosphérique',])\n",
    "    \n",
    "    if graph_choisi == 'Corrélation entre nuages et pluie le lendemain':\n",
    "      st.image('Cloud9am_RainTomorrow.jpg')\n",
    "      st.write(\"Le pourcentage de nuages à 9h du matin est concentré sur les valeurs élevées lorsqu'il a plu le lendemain (yes) - boite Orange.\")\n",
    "      st.write(\"En revanche, on voit s'agissant de la boite bleue (No) indiquant qu'il n'a pas plu le lendemain, que la distribution de la densité de nuages à 9h du matin est bien plus large, et donc moins porteuse d'information\")  \n",
    "    \n",
    "    if graph_choisi == 'Corrélation entre ensoleillement et précipitation en mm':\n",
    "      fig = plt.figure(figsize=(10, 4))\n",
    "      sns.lineplot(data= df_raw,x=\"Sunshine\",y=\"Rainfall\",color = \"green\");\n",
    "      st.pyplot(fig)\n",
    "      st.write(\"Nous pouvons voir que l'ensoleillement est inversement proportionnel aux précipitations:\")\n",
    "    \n",
    "    if graph_choisi == 'Corrélation entre ensoleillement et évaporation':\n",
    "      fig = plt.figure(figsize=(10, 4))\n",
    "      sns.lineplot(data= df_raw,x=\"Sunshine\",y=\"Evaporation\",color = \"blue\");\n",
    "      st.pyplot(fig) \n",
    "      st.write(\"Phénomène inverse, nous pouvons voir que l'ensoleillement (heures) est proportionnel avec l’évaporation (mm)\")\n",
    "\n",
    "    if graph_choisi == 'Distribution de fréquence de la variable RainTomorrow':\n",
    "      st.image('RainTommorow_count.jpg')\n",
    "      st.write(\"Notre première expression à la vue de cette figure est que l'Australie n'est apparemment pas un territoire où il pleut beaucoup. Comme l'indiquent les chiffres, la majorité des journées ne connaissent pas de précipitation. Une répartition totalement déséquilibrée susceptible d'influencer notre modélisation \")\n",
    "      st.write(\"Dans le langage de la science des données, c'est ce qu'on appelle un Dataset déséquilibré (78%,  22%)\")\n",
    "    \n",
    "    if graph_choisi == 'corrélation entre humidité et RainTomorrow':\n",
    "      fig = plt.figure(figsize=(10, 4)) \n",
    "      sns.boxplot(data= df_raw,x='RainTomorrow',y = \"Humidity3pm\");\n",
    "      st.pyplot(fig)\n",
    "      st.write(\"Le pourcentage d'humidité à 15 heures est élevé les jours où il a plu le lendemain.\")\n",
    "      \n",
    "    if graph_choisi == 'Influence des saisons':\n",
    "      st.image('serie_temp_date.jpg')\n",
    "      st.image('influence_month.jpg')\n",
    "      st.write(\"Les deux graphiques ci-dessus indiquent clairement l’influence (significative) des mois/saisons sur les variables (exemple ici avec les variables MinTemp et MaxTemp). Nous observons bien une tendance stationnaire ainsi qu’une saisonnalité à l’échelle de l’année .\")\n",
    "    \n",
    "    if graph_choisi == 'Influence de la pression atomosphérique':\n",
    "      st.write(\"Pression moyenne : 1013.25hPa au niveau de la mer.\")\n",
    "      st.write(\"Le pression change en fonction de l'altitude : environ 900hPa à 1000m, 700hPa à 3000m.\")\n",
    "      st.write(\"Les météorologues analysent donc les variations de pression (dépressions et anticyclones) pour ne pas avoir à intégrer l'altitude dans les calculs.\")\n",
    "      st.write(\"Nous allons créer une nouvelle colonne 'Pressur_diff' qui prendra en compte la différence de pression entre 9am et 3pm.\")\n",
    "      with st.echo():       # pour afficher une partie du code\n",
    "        df_raw['Pressure_diff']=df_raw['Pressure3pm']-df_raw['Pressure9am']\n",
    "      \n",
    "      fig = plt.figure(figsize=(10,6))\n",
    "      sns.boxenplot(x='RainTomorrow',y='Pressure_diff',data=df_raw);\n",
    "      st.pyplot(fig)\n",
    "\n",
    "      st.write(\"Bien que le résultat visuel n'indique pas de manière évidente l'impact devariation de pression sur la précipitation, celle-ci est bien démontrée par un test statistique :\")\n",
    "      result=statsmodels.formula.api.ols('Pressure_diff~RainTomorrow',data=df_raw).fit()\n",
    "      table=statsmodels.api.stats.anova_lm(result)\n",
    "        \n",
    "      st.write(\"la p-value est très inférieure à 5% ==> l'hypothèse H0 est donc rejetée\")\n",
    "  \n",
    "  with st.expander(\"Nettoyage\"):\n",
    "  #st.markdown(\"## Nettoyage\")\n",
    "\n",
    "    ## checkbox\n",
    "    if st.checkbox('Afficher valeurs manquantes'):\n",
    "      st.dataframe(df_explore.isna().sum())\n",
    "\n",
    "      st.write(\"Avant de réaliser la modélisation , il était nécessaire de procéder à quelques traitements des données. Nous avons commencé par faire un regroupement des villes par Etat (State).\\\n",
    "      Ensuite, Nous avons diviser la  colonne date en jour, mois et année car elle a un impact sur les prédictions\")\n",
    "\n",
    "    with st.echo():       \n",
    "      df_raw['Year']=pd.to_datetime(df_raw['Date']).dt.year\n",
    "      df_raw['Month']=pd.to_datetime(df_raw['Date']).dt.month\n",
    "      df_raw['Day']=pd.to_datetime(df_raw['Date']).dt.day\n",
    "      \n",
    "    st.write(\"Afin de traiter les treize colonnes avec NA de notre ensemble des données, et comme nous l’avons vu précédemment, il y a une saisonnalité à l’échelle de l’année sur l’ensemble des données recueillies\" \n",
    "            \" Nous avons donc décidé de :\")\n",
    "\n",
    "    st.write(\"1 - Faire un regroupement des variables par mois ( groupby('Month'))\")\n",
    "    st.write(\"2 - Remplacer les Na par la moyenne observée durant le mois \")\n",
    "    st.write(\"3 - Supprimer les colonne avec un taux qui avoisine 50'%' de Na (insignifiante pour les calculs)\")\n",
    "    st.write(\"4 - Supprimer l'année 2007 et 2008 (Relevés fortement minoritaires, et présentants des valeurs abbérantes en surnombre)\")\n",
    "  \n",
    "    if st.checkbox(\"Afficher les Relevés par année\"):\n",
    "      st.image('Afficher les Relevés par année.jpg')\n",
    "      \n",
    "    st.write(\"5 - Supprimer toutes les observations compartant des Na pour notre variable cible\")\n",
    "              \n",
    "  with st.expander(\"Preprocessing\"):\n",
    "    #st.markdown(\"## Preprocessing\")\n",
    "    st.write(\"Il est impératif de bien préparer nos données avant leur passage dans la machine.\")         \n",
    "    st.write(\"**Tout d'abord nous examinons les colonnes catégorielles** de notre ensemble de données\")   \n",
    "    if st.checkbox(\"Afficher les variables catégorielles\"):\n",
    "      st.image('Variables.jpg')\n",
    "    st.caption(\"Dichotomisation des variables qualitatives\")\n",
    "\n",
    "    with st.echo():       \n",
    "      list_dichotom=['WindGustDir','WindDir9am','WindDir3pm','Cloud9am','Cloud3pm','State','Year','Month','Day']\n",
    "      #df=pd.get_dummies(data=df,columns=list_dichotom)\n",
    "    st.write(\"Nous avons choisi la méthode **get_dummies** pour adresser la problématqiue de hiérarchie.\")\n",
    "    \n",
    "    '''\n",
    "    st.caption(\"Graphe d'évolution de pluviométrie\")\n",
    "    st.image('evolution.jpg')\n",
    "    st.write(\"Le graphe ci-dessus confirme la saisonnalité et notre choix d'extraction de l'année du mois\")\n",
    "    '''\n",
    "    \n",
    "    st.caption(\"Standarisation\")\n",
    "    st.write(\"Nous pouvons  clôturer cette étape de preprocessing par une **normalisation** qui permet de mettre sur\\\n",
    "    une même échelle toutes les variables quantitatives en utilisant la méthode **StandardScaler()**\")\n",
    "    st.image(\"scaler.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "##############################################\n",
    "##### SELECTION DES VARIABLES INFLUENTES #####\n",
    "##############################################\n",
    "\n",
    "def feature_select():\n",
    "  st.title('Sélection des variables influentes')\n",
    "  \n",
    "  df = pd.read_csv('weatherAUS_raw.csv')\n",
    "  st.markdown(\"<style>.streamlit-expanderHeader {font-size: x-large;}</style>\",unsafe_allow_html=True)   # pour configurer la police de st.expander\n",
    "  with st.expander(\"1. Rapel du taux de valeurs manquantes:\"):\n",
    "    st.dataframe( ((df.isna().sum())/df.shape[0]).sort_values(ascending=False))\n",
    "    st.write(\"Le premier volet de la sélection des variable porte sur la prise en compte ou non des variables comportant des taux importants de NA.\")\n",
    "    st.write(\"Il est communément observé qu’un seuil de 25 à 30 % de valeurs manquantes peut être acceptable. Au-delà, les caractéristiques concernées doivent être supprimées de l'analyse. Il s’agit dans notre cas de :\")\n",
    "    st.image(\"cycle de l'eau.PNG\")\n",
    "    st.write(\" ### - Sunshine\")\n",
    "    st.write(\"L'ensoleillement est lié au début du cycle de l'eau.\")\n",
    "    st.write(\"**avis métier :** a priori pas d'impact immédiat sur la pluie du lendemain > **supprimer** \")\n",
    "    st.write(\" ### - Evaporation\")\n",
    "    st.write(\"L'évaporation est l'une des premières étapes du cycle de l'eau ou de la pluie.\")\n",
    "    st.write(\"**avis métier :** a priori pas d'impact direct sur la pluie du lendemain > **supprimer**\")\n",
    "    st.write(\" ### - Cloud\")    \n",
    "    st.write(\"La formation de nuages précède la précipitation dans le cycle de l'eau ou de la pluie.\")\n",
    "    st.write(\"**avis métier :** il y a donc un lien  direct entre nuages et pluie > **garder**\")\n",
    "\n",
    "  with st.expander(\"2. La distribution des variables numériques:\"):\n",
    "    st.write(\"Le second volet abordant la sélection des variables se base sur l’analyse de la distribution des variables\")\n",
    "    df_quantitative = [column for column in df.columns if df[column].dtype == float]\n",
    "    df_quantitative_not_Pressure = [column for column in df_quantitative if column not in ['Pressure9am', 'Pressure3pm']]\n",
    "    if st.checkbox('Distribution de **toutes** les variables quantitatives:', value = True):\n",
    "      fig = plt.figure(figsize=(10,10))\n",
    "      df.boxplot(column = df_quantitative)\n",
    "      plt.xticks(rotation=90)\n",
    "      st.pyplot(fig)\n",
    "      st.write(\"les valeurs de pression sont beaucoup plus grandes que les autres variables, et ont donc tendance à les écraser en affichage. Par conséquent, afin de mieux visualiser la distribution, nous présentons les variables (cf. figure ci-dessous) sans les 2 variables de pression\")\n",
    "    if st.checkbox('Distribution des variables quantitatives **sans** les variables Pression:', value = False):\n",
    "      fig = plt.figure(figsize=(10,10))\n",
    "      df.boxplot(column = df_quantitative_not_Pressure)\n",
    "      plt.xticks(rotation=90)\n",
    "      st.pyplot(fig)\n",
    "      st.write(\"De nombreux points semblent atypiques dans la variable Rainfall. Mais sont-ils des outliers pour autant ?\")\n",
    "\n",
    "    st.write(\"### Les outliers?\")\n",
    "    if st.checkbox('Afficher les détails de RainFall'):\n",
    "      fig, axs = plt.subplots(1,2,figsize=(18, 5))\n",
    "      sns.histplot(x='Rainfall',data = df,bins=20, kde=True,ax=axs[0])\n",
    "      sns.boxplot(x='Rainfall', data = df,ax = axs[1], color='#99befd', fliersize=1)\n",
    "      st.pyplot(fig)\n",
    "      st.write(\"Ces points atypiques  correspondent bien à des points observés dans la réalité. En effet, dans les zones plutôt sèches, le nombre de jours sans pluie peut être important. Mais de manière exceptionnelle, il peut y avoir une pluie forte avec une précipitation supérieure à 200mm. Nous décidons donc de ne pas corriger ces données.\")\n",
    "    st.write(\"**Par conséquent, il n'y a pas de traitement effectué dans cette partie de l’analyse.**\")\n",
    "\n",
    "  with st.expander(\"3. Corrélation entre variables explicatives:\"):\n",
    "    st.write(\"Nous réalisons une analyse de corrélation entre les variables explicatives quantitatives. Nous faisons cette analyse à l’aide d’une heatmap\")\n",
    "    st.image('heatmap.PNG')\n",
    "    st.write(\"Nous pouvons constater dans la heatmap qu’il existe une forte corrélation entre certains variables:\")\n",
    "    st.write(\" - Temp3pm and MaxTemp  **98%**\")\n",
    "    st.write(\" - Pressure3pm and Pressure9am  **96%**\")\n",
    "    st.write(\" - Temp9am and MinTemp   **91%**\")\n",
    "    st.write(\" - Temp9am and MaxTemp  **89%**\")\n",
    "    st.write(\" - Temp3pm and Temp9am  **87%**\")\n",
    "    st.write(\"Nous pouvons confirmer ces corrélations par les tests de corrélation de Pearson\")\n",
    "    if st.checkbox('Afficher les p_value'):\n",
    "      st.image('p_value_var_corr.PNG')\n",
    "    st.write(\"Au-delà de 50%, il est possible de considérer que la corrélation est forte entre 2 variables.  Pour éviter de supprimer trop d’ informations , nous ne  regardons que les variables avec une corrélation supérieure à 80%\")\n",
    "    st.write(\"Par conséquent, nous pourrons supprimer les variables suivantes : **MaxTemp, MinTemp, Pressure3pm**\")\n",
    "   \n",
    "  with st.expander(\"4. L’impact des variables (quantitatives) sur la cible - visualisation:\"):\n",
    "    st.write(\"Nous nous intéressons à la corrélation entre les variables explicatives (quantitatives) et la variable cible. Pour cela nous utilisons une approche  basée sur des visualisations.\")\n",
    "    st.write(\"Lorsque les zones bleue et orange coincident, la variable explicative n'a alors pas ou peu d'impact sur la variable cible.\")\n",
    "    st.image('impact sur la cible.PNG')\n",
    "    st.write(\"Nous pouvons ainsi voir que la variable Sunshine, par exemple, a un impact sur la variable cible, comme les zones bleue et orange sont bien disjointes.\")\n",
    "    st.write(\"Au final, nous pourrons supprimer les variables suivantes qui ne sont pas impactantes pour la variable cible : **MaxTemp, Evaporation, WindSpeed9am, WindSpeed3pm, Temp9am**\")\n",
    "\n",
    "  with st.expander(\"5. Model Feature selection:\"):\n",
    "    st.write(\"Avec sklearn, il est possible de sélectionner k features (ou variables) des features de notre dataset avec le sélecteur **SelectKBest**, qui se base sur une métrique prédéfinie (score_func). Tel est l’objet de cette partie de l’analyse\")\n",
    "    st.write(\"Pour ce faire, nous avons séparé les variables (quantitatives d’une part, et explicatives d’autre part) et appliqué les métriques suivantes :\")\n",
    "    st.write(\" - chi2 **>** pour les variables qualitatives\")\n",
    "    st.write(\" - mutual_info_classif et f_classif **>** pour les variables quantiatives\")\n",
    "    st.write(\"**Résultat:**\")\n",
    "    st.image('selectKBest_1.PNG')\n",
    "    st.write(\"La liste de variables pour la modélisation : \")\n",
    "    st.write(\"**RainToday, Cloud9am_0.0, Cloud3pm_8.0,Cloud9am_8.0,Cloud3pm_1.0, Humidity_9am, Pressure_diff, Sunshine, Humidity_3pm, Rainfall**\")\n",
    "\n",
    "\n",
    "    df_feature = pd.read_csv('feature_selection.csv')\n",
    "\n",
    "    if st.checkbox('Analyses complémentaires'):\n",
    "      st.write(\"#### Traitement des variables Cloud\")\n",
    "      st.caption(\"Cloud > groupe quantitatif\")\n",
    "      st.write(\"Le feature score des variables Cloud est faible, et donc conduirait à ne pas les garder en première approche.\")\n",
    "      st.write(\"Toutefois, nous nous rendons compte qu’il faut peut-être traiter le variable Cloud comme une variable quantitative. Même si les valeurs sont discrètes, comme 0,1, etc. mais La définition de Cloud est le pourcentage de surface du ciel couvert par le nuage. Par exemple Cloud =1, veut dire, 10% de ciel est couvert par le nuage\")\n",
    "      C9_RTm = pd.crosstab(df_feature['Cloud9am'],df_feature['RainTomorrow'], normalize= 0)\n",
    "      C9_RT = pd.crosstab(df_feature['Cloud9am'],df_feature['RainToday'], normalize= 0)\n",
    "      C3_RT = pd.crosstab(df_feature['Cloud3pm'],df_feature['RainToday'], normalize= 0)\n",
    "      C3_RTm = pd.crosstab(df_feature['Cloud3pm'],df_feature['RainTomorrow'], normalize= 0)\n",
    "      fig = plt.figure(figsize=(4,4))\n",
    "      plt.plot(C9_RT.index,C9_RTm[1], label = 'C9am_RainTomorrow')\n",
    "      plt.plot(C9_RT.index,C9_RT[1], label = 'C9am_RainToday')\n",
    "      plt.plot(C3_RT.index,C3_RTm[1], label = 'C3pm_RainTomorrow')\n",
    "      plt.plot(C3_RT.index,C3_RT[1], label = 'C3pm_RainToday')\n",
    "      plt.xlabel('Cloud level')\n",
    "      plt.ylabel('Probability of rain')\n",
    "      plt.legend()\n",
    "      st.pyplot(fig)\n",
    "      st.write(\"Ces courbes montrent bien une forte corrélation entre le nuage (à 9h et à 15h) et la pluie (aujourd’hui et demain). **Nous décidons donc de garder ces 2 variables Cloud**.\")\n",
    "\n",
    "      st.write(\"#### Des résultats différents selon la valeur de K ?\")\n",
    "      st.write(\"Nous avons constaté des résultats différents en fonction de la valeurs de K:\")\n",
    "      st.image('selectKBest_1_k=5_10_20.PNG')\n",
    "\n",
    "      st.write(\"Après, nous avons lancé une 2ème fois le SelectKBest, cette fois sur le dataset initial (seulement corrigé des NA), et nous essayons de vérifier si les résultats sont 'corrects': \")\n",
    "      st.image('selectKBest_2_qualitative.PNG')\n",
    "\n",
    "      st.write(\"##### L'impact de RainToday sur RainTomorrow\")\n",
    "      st.write(\"RainToday continue à occuper la première place.\")\n",
    "      st.image('impact_raintoday_raintomorrow.PNG')\n",
    "      st.write(\"Pour la 2e place, nous avons state_Norfolk\")\n",
    "\n",
    "      st.write(\"##### L'impact de NorfolkIsland sur RainTomorrow:\")\n",
    "      st.write(\"Nous avons trouvé les informations suivantes : \")\n",
    "      st.image('AUS Rainfall 2021.PNG')\n",
    "      st.image('Norfolk rain.PNG')\n",
    "      st.write(\"C’est une île, où la précipitation est assez élevée par rapport aux autres Etats (sauf Tasmania où la pluviométrie est équivalente, autour de 1300 mm comme indiqué dans les figures ci-dessous). **Nous pouvons considérer que Norfolk Island influe beaucoup sur la prédiction de la pluie**, donc cette deuxième position est donc compréhensible.\")\n",
    "      st.image('AUS Rainfall 2021 supposition.PNG')\n",
    "\n",
    "      st.write(\"##### L'impact de WindDirction sur RainTomorrow:\")\n",
    "      st.image('Winddir impact.PNG')\n",
    "      st.write(\"Les 2 courbes (orange et bleue) ne sont pas confondues, les directions de vent portent un impact sur la pluie, mais il est difficile de conclure parmi les 16 directions, **nous pouvons garder toutes les variables ‘Wind’ avec une importance positive**\")\n",
    "\n",
    "      st.write(\"##### L'impact de Month sur RainTomorrow:\")\n",
    "      st.write(\"Nous avons pensé que ‘Month’ pourrait avoir un impact sur la pluie, mais il n'a pas été choisi par SelectKBest. Nous avons vérifié ce point avec la graphique de comparaison\")\n",
    "      st.image('impact month.PNG')\n",
    "      st.write(\"L’écart entre les 2 courbes (orange/bleue) est très faible. **Nous pouvons considérer que  ‘Month’ n’est pas une variable importante pour la prédiction de pluie**, confirmant le résultat de KBest\")\n",
    "      st.write(\"##### Les variables quantitatives:\")\n",
    "      st.image('selectKBest_quantitative.PNG')\n",
    "\n",
    "  with st.expander(\"Conclusion:\"):\n",
    "    st.write(\"La combinaison des analyses précédentes nous conduit à retenir les variables suivantes pour la modélisation : \")\n",
    "    st.write(\"**Pressure9am, Sunshine, Temp3pm, Cloud3pm, Humidity3pm, Rainfall, WindGustSpeed, RainToday, State_NorfolkIsland, WindDir3pm_W, WindGustDir_W, WindGustDir_NW, WindDir3pm_NW, WindDir9am_NNE, WindDir9am_E, WindDir9am_ENE**\")\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "##### MODELISATIONS #####\n",
    "#########################\n",
    "\n",
    "def models():\n",
    "  st.title('Les modélisations')\n",
    "  st.write(\"Divers algorithmes de classification supervisée ont été testés. Afin d'en tirer les meilleures performances, un tunning des hyperparamètres par validation croisée (GridSearchCV) a été effectué sur chacun de ces algorithmes.\")\n",
    "  st.write(\"\")\n",
    "\n",
    "  # partie JL\n",
    "  if st.checkbox('Rappel de la liste de variables utilisées'):\n",
    "    st.write(\"Pressure9am, Sunshine, Temp3pmn Cloud3pm, Humidity3pm, Rainfall, WindGustSpeed, RainToday, State_NorfolkIsland, WindDir3pm_W, WindGustDir_W, WindGustDir_NW, WindDir3pm_NW, WindDir9am_NNE, WindDir9am_E, WindDir9am_ENE\")\n",
    "\n",
    "  st.markdown(\"<style>.streamlit-expanderHeader {font-size: x-large;}</style>\",unsafe_allow_html=True)   # pour configurer la police de st.expander\n",
    "  with st.expander(\"Régression logistique\"):\n",
    "    st.image('model_lr.PNG')\n",
    "\n",
    "  with st.expander(\"Arbre de décision\"):\n",
    "    st.image('model_dt.PNG')\n",
    "\n",
    "  with st.expander(\"Random Forest\"):\n",
    "    st.image('model_rf.PNG')\n",
    "  \n",
    "  with st.expander(\"XG Boost\"):\n",
    "    st.image('model_xgboost.PNG')\n",
    "\n",
    "  with st.expander(\"Voting\"):\n",
    "    st.write(\"L'algorithme d'ensemble learning \\\"Voting\\\" a été entraîné avec les modèles essayés ci-dessus. Les meilleurs hyperparamètres ont été retenus. Nous avons ainsi utilisé la régression logistique, les arbres de décision, la random forest et le KNN. Il en ressort des résultats au moins aussi bons que le meilleur des modèles, sans toutefois le surpasser.\")   \n",
    "    st.image('Voting.PNG')\n",
    "\n",
    "  with st.expander(\"Stacking\"):\n",
    "    st.write(\"Pour cet algorithme d'ensemble learning de \\\"Stacking\\\", la façon de procéder est la même que le voting ci-dessus. Nous obtenons également des résultats au moins aussi bons que le meilleur des modèles, sans toutefois le surpasser.\")   \n",
    "    st.image('Stacking.PNG')\n",
    "\n",
    "  with st.expander(\"Deep learning\"):\n",
    "    st.write(\"Nous avons pour terminer entraîné un modèle de type \\\"multi-layer perceptron\\\". Les meilleurs résultats ont été obtenus avec une architecture à 3 couches. Les 2 premières comportent 32 neurones quand la dernière en compte 2. L'optimizer est Adam et le learning rate défini à 0.001. La fonction de perte utilisée est binary_crossentropy. Nous avons entraîné le modèle sur une taille de batch de 10 et 40 epochs.\")   \n",
    "    st.image('Deep_Learning.PNG')\n",
    "    st.write(\"Un callback de type ReduceLROnPlateau a été mis en place et nous constatons bien son action sur la courbe de train_loss\")\n",
    "    st.write(\"Nous obtenons ici les meilleurs résultats tous modèles confondus avec une accuracy sur le dataset de validation de plus de 0.835!\")\n",
    "\n",
    "  with st.expander(\"Conclusion comparative\"):\n",
    "    st.write(\"Le modèle donnant le meilleur score est le XGBoost avec un F1-score de 0.83. Il est suivi de très près par le perceptron multi-couches. Ce dernier offre cependant la meilleur accuracy avec 0.84. Aucun de ces modèles ne sort particulièrement du lot.\")   \n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "##### PAGE DES CONTACTS #####\n",
    "#############################\n",
    "\n",
    "def contacts():\n",
    "  st.title('Contacts des participants au projet')\n",
    "  st.markdown(\"### Yassine HAMDAOUI\")\n",
    "  st.write(\"[link](https://www.linkedin.com/in/yassine-hamdaoui-17a738131/?originalSubdomain=fr)\")\n",
    "  st.markdown(\"### JingYi LIU\")\n",
    "  st.write(\"[link](https://www.linkedin.com/in/jingyi-liu-370b5055/)\")\n",
    "  st.markdown(\"### Julien PROST\")\n",
    "  st.write(\"[link](https://www.linkedin.com/in/julien-prost-360aab107/)\")\n",
    "  st.markdown(\"### Mohamed TOUMI\")\n",
    "  st.write(\"[link](https://www.linkedin.com/in/mohamed-toumi-30035917/)\")\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "##### PAGE DU BILAN ET PERSPECTIVES #####\n",
    "#########################################\n",
    "\n",
    "def perspectives():\n",
    "  st.title('Bilan et perspectives')\n",
    "  st.caption('regard critique sur le déroulement et les résultats du projet')\n",
    "  st.write(\"En prenant un peu de recul sur le projet, nous pouvons retenir notamment les deux éléments suivants comme structurants pour la construction d'une modélisation robuste.\")\n",
    "  st.write(\"Tout d'abord, la **sélection des variables**:\")\n",
    "  st.write(\"Le preprocessing nous a rapidement conduit à traiter un grand nombre de variables (plus de 140), rendant les modèles de machine learning très lents, voire impossibles à exécuter pour certains, sur nos machines.\")\n",
    "  st.write(\"La partie sélection des variables a donc été fondamentale dans la définition de notre modèle.\")\n",
    "  st.write(\"La difficulté a été de faire la passerelle entre les variables métier d'une part, qui selon toute vraisemblance doivent avoir un rôle important à jouer dans la classification de la cible, et d'autre part, les variables issues des analyses de corrélation.\")\n",
    "  st.write(\"Cette analyse est d'autant plus ardue qu'elle nécessite de prendre en compte certains biais, comme un nombre important de NA pour certaines variables, ou encore la prise en compte de certaines variables comme quantitatives plutot que qualitatives.\")\n",
    "  st.write(\"Enfin, un axe de travail qui nécessite un effort d'investigation supplémentaire à l'issue de ce projet, consiste à comprendre ce qui peut conduire à l'obtention de listes de variables différentes selon la valeur du K choisi pour un Select KBest\")\n",
    "  st.write(\"Cette problématique nous a conduit, comme nous l'indiquons dans le rapport du projet, à mener des analyses poussées, en deux temps, de la pertinence des variables, en nous reposant notamment le plus possible sur les connaissances métier.\")\n",
    "\n",
    "  st.write(\"\\n\")\n",
    "  st.write(\"Ensuite, l'affinage des paramètres du **modèle de deep learning**:\")\n",
    "  st.write(\"Après avoir mis en oeuvre les algorithmes classiques de machine learning, nous avons essayé de construire un algorithme de deep learning.\")\n",
    "  st.write(\"Comme indiqué dans la rubrique correspondante, cet algoritme nous a permis d'obtenir les meilleurs résultats de classification.\")\n",
    "  st.write(\"Toutefois, nous avons manqué de temps pour affiner, autant que faire se peut, le choix des hyperparamètres de ce modèle. Il s'agit donc d'un axe de travail supplémentaire identifé pour l'après-projet\")\n",
    "  st.write(\"Une ouverture serait de tester un modèle de deep learning avec architecture RNN afin d'étudier la séquentialité des données. Peut-être l'étude sur 10 jours glissants permettrait d'être plus précis dans les prévisions\")\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "##### AFFICHAGE DU MENU #####\n",
    "#############################\n",
    "\n",
    "with st.sidebar:\n",
    "  selected = option_menu(menu_title = 'Menu principal',\n",
    "                         options = ['Introduction', 'Dataset', 'Analyse exploratoire', 'Sélection des variables', 'Modélisations', 'Bilan et perspectives', 'Contacts'],\n",
    "                         default_index = 0)\n",
    "\n",
    "if selected == 'Introduction':\n",
    "  introduction()\n",
    "if selected == 'Dataset':\n",
    "  dataset(df_raw)\n",
    "if selected == 'Analyse exploratoire':\n",
    "  data_explore(df_raw)\n",
    "if selected == 'Sélection des variables':\n",
    "  feature_select()\n",
    "if selected == 'Modélisations':\n",
    "  models()\n",
    "if selected == 'Contacts':\n",
    "  contacts()\n",
    "if selected == 'Bilan et perspectives':\n",
    "  perspectives()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3gsQSTtXP3W"
   },
   "source": [
    "## **EXECUTION DU STREAMLIT**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94453,
     "status": "ok",
     "timestamp": 1655812049364,
     "user": {
      "displayName": "bds meteo",
      "userId": "09881294319658969130"
     },
     "user_tz": -120
    },
    "id": "As38prE8S42W",
    "outputId": "17452f6e-a993-4ea1-a06a-8ae580ab1b5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 11:45:56.196 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.232.151.60:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[K\u001b[?25hnpx: installed 22 in 3.105s\n",
      "your url is: https://purple-comics-move-35-232-151-60.loca.lt\n",
      "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# ICI ON EXEXUTE app.py DANS LEQUEL NOUS AVONS ECRIT LE CODE CI-DESSUS\n",
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "streamlit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
